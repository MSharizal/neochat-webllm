<div align="center">

<p align="center">
  <img src="./banner.svg" alt="NeoChat â€¢ WebLLM banner" width="100%"/>
</p>


# ğŸ§  **NeoChat â€¢ WebLLM**  
### _A Browser-Native AI Built for the Future_  

ğŸŒ **Live Demo:** [msharizal.github.io/neochat-webllm](https://msharizal.github.io/neochat-webllm)  
ğŸ§© Powered by [WebLLM (MLC.ai)](https://webllm.mlc.ai) â€¢ âš™ï¸ Runs Locally â€¢ ğŸ” 100% Private  

</div>

---

### âœ¨ Overview  
**NeoChat** is a **next-generation, browser-based LLM** that runs **entirely on your device** â€” no servers, no API keys, and zero data leakage.  
Powered by **WebGPU**, it demonstrates the future of **client-side AI**: lightweight, private, and blazing fast.  
The entire app lives in one elegant file: `index.html`.

---

### âš¡ Features  
- ğŸ§© **100% Local Execution** â€“ inference runs directly in your browser with WebGPU  
- ğŸŒ **Bilingual Support** â€“ optimized for English + Malay (Qwen-Instruct models)  
- ğŸ§  **Model Switcher** â€“ toggle between Qwen 2.5, Llama 3.2 & SmolLM  
- ğŸ’« **Glassmorphic UI** â€“ minimalist, futuristic interface powered by TailwindCSS  
- ğŸ’¬ **Streaming Generation** â€“ token-by-token responses in real time  
- ğŸ” **Privacy-First** â€“ nothing leaves your device, ever  
- ğŸª¶ **One-File Architecture** â€“ deploy anywhere instantly (e.g., GitHub Pages)

---

### ğŸ§° Tech Stack  

| Component | Description |
|------------|-------------|
| **WebLLM** | WebGPU-accelerated LLM inference |
| **TailwindCSS** | Utility-first design system |
| **HTML + ES Modules** | Lightweight, framework-free front-end |
| **GitHub Pages** | Free static hosting for AI web apps |

---

### âš™ï¸ Quick Setup (Local Use)  

> ğŸ§  **Note:** WebGPU support is required. Follow these steps to enable it.

**1ï¸âƒ£ Update Browser**  
- **Chrome:** â‹® â†’ Help â†’ About Google Chrome  
- **Edge:** â€¦ â†’ Help and feedback â†’ About Microsoft Edge  

---

#### 2ï¸âƒ£ **Enable WebGPU Flag**
Paste one of these in your address bar and set to **Enabled â†’ Relaunch**

- ğŸ”— **[Open in Chrome](chrome://flags/#enable-unsafe-webgpu)**  
- ğŸ”— **[Open in Edge](edge://flags/#enable-unsafe-webgpu)**  

---

**3ï¸âƒ£ Enable Hardware Acceleration**  
Settings â†’ System â†’ â€œUse hardware acceleration when availableâ€ â†’ ON â†’ Restart browser  

**4ï¸âƒ£ Force GPU Mode (Windows)**  
System â†’ Display â†’ Graphics â†’ Select Chrome â†’ Options â†’ High performance â†’ Save  

---

### ğŸ§  Recommended Models  

| Model | Size | Notes |
|--------|------|-------|
| `Qwen2.5-0.5B-Instruct-q4f32_1-MLC` | ğŸª¶ Tiny | Fast & multilingual |
| `Qwen2.5-1.5B-Instruct-q4f32_1-MLC` | âš–ï¸ Medium | Balanced performance |
| `Llama-3.2-1B-Instruct-q4f32_1-MLC` | ğŸ’¡ Medium | Great English fluency |
| `SmolLM2-1.7B-Instruct-q4f16_1-MLC` | ğŸ§© Large | Better reasoning depth |

_First download may take a minute; future sessions load instantly from cache._

---

### ğŸª© Vision  
> â€œThe future of AI isnâ€™t on distant servers â€” itâ€™s right in your browser.â€  

**NeoChat** is a glimpse into the **WebGPU era**, where AI inference is local, secure, and lightning fast.  
Build. Fork. Remix. Deploy your own **personal LLM portal** â€” no cloud required.  

---

### ğŸ‘¨â€ğŸš€ Author  
**Sharizal Shafiq**  
[ğŸ”— LinkedIn](https://www.linkedin.com/in/msharizal) â€¢ [ğŸ’» GitHub](https://github.com/MSharizal)

---

### ğŸªª License  
**MIT License Â© 2025** â€“ Free to use, modify, and deploy.

---

<div align="center">

âš¡ **Built for the WebGPU Generation**  
ğŸ’œ **NeoChat â€” Where AI Meets the Browser**

</div>
