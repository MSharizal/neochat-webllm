# ğŸ§  NeoChat â€¢ WebLLM (Browser-Only)

A **futuristic, lightweight AI chat** that runs **entirely in your browser** â€” no server, no API key, no cost.  
Built with [WebLLM (MLC.ai)](https://webllm.mlc.ai/) and designed to be hosted **free on GitHub Pages**.

---

## âš¡ Features

- ğŸ§© **100% Client-Side** â€” runs locally in your browser via WebGPU (no backend)
- ğŸŒ **Multilingual Ready** â€” English + Malay (Qwen-Instruct models)
- ğŸš€ **One-File App** â€” just `index.html`
- ğŸ’« **Futuristic Glass UI** â€” powered by TailwindCSS
- âš™ï¸ **Model Selector** â€” switch between Qwen2.5, Llama-3.2, and SmolLM
- ğŸ’¬ **Streaming Responses** â€” token-by-token generation
- ğŸ” **Privacy-First** â€” nothing leaves your device

---

## ğŸ§° Tech Stack

| Component | Description |
|------------|-------------|
| **WebLLM** | In-browser LLM inference with WebGPU |
| **TailwindCSS** | Styling and responsive layout |
| **HTML + JS (ESM)** | No build tools needed |
| **GitHub Pages** | Free static hosting |

---

## ğŸ§© Quick Start (Local)

```bash
# clone this repo
git clone https://github.com/MSharizal/neochat-webllm.git
cd neochat-webllm

# open index.html in your browser
