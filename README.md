# 🧠 NeoChat • WebLLM (Browser-Only)

A **futuristic, lightweight AI chat** that runs **entirely in your browser** — no server, no API key, no cost.  
Built with [WebLLM (MLC.ai)](https://webllm.mlc.ai/) and designed to be hosted **free on GitHub Pages**.

---

## ⚡ Features

- 🧩 **100% Client-Side** — runs locally in your browser via WebGPU (no backend)
- 🌍 **Multilingual Ready** — English + Malay (Qwen-Instruct models)
- 🚀 **One-File App** — just `index.html`
- 💫 **Futuristic Glass UI** — powered by TailwindCSS
- ⚙️ **Model Selector** — switch between Qwen2.5, Llama-3.2, and SmolLM
- 💬 **Streaming Responses** — token-by-token generation
- 🔐 **Privacy-First** — nothing leaves your device

---

## 🧰 Tech Stack

| Component | Description |
|------------|-------------|
| **WebLLM** | In-browser LLM inference with WebGPU |
| **TailwindCSS** | Styling and responsive layout |
| **HTML + JS (ESM)** | No build tools needed |
| **GitHub Pages** | Free static hosting |

---

## 🧩 Quick Start (Local)

```bash
# clone this repo
git clone https://github.com/MSharizal/neochat-webllm.git
cd neochat-webllm

# open index.html in your browser
